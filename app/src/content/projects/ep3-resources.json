{
  "id": "ep3-resources",
  "slug": "ep3-resources",
  "title": "Episode 3: Additional Resources",
  "date": "2024-10-16",
  "category": "Episode Resources",
  "tags": ["RAG", "Vector DB", "Resources"],
  "featured": false,
  "excerpt": "Links and resources mentioned in Episode 3 with our commentary.",
  "content": "Links and resources mentioned in our conversation with Marcus Johnson from VectorDB Inc.\n\n## Tools Mentioned\n\n### Vector Databases\n- **Pinecone** - Managed vector database with excellent documentation\n- **Weaviate** - Open-source vector search engine\n- **Chroma** - Lightweight, embeddable vector database\n- **Qdrant** - High-performance vector similarity search\n\n### Embedding Models\n- **OpenAI text-embedding-3** - Strong general-purpose embeddings\n- **Cohere embed** - Good multilingual support\n- **Sentence Transformers** - Open-source, self-hostable\n\n### RAG Frameworks\n- **LangChain** - Popular orchestration framework\n- **LlamaIndex** - Data-centric RAG framework\n- **Haystack** - End-to-end NLP framework\n\n## Key Papers\n\n1. **\"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\"** (Lewis et al., 2020)\n   - The foundational RAG paper\n\n2. **\"Dense Passage Retrieval for Open-Domain Question Answering\"** (Karpukhin et al., 2020)\n   - DPR approach to retrieval\n\n3. **\"Improving Language Models by Retrieving from Trillions of Tokens\"** (Borgeaud et al., 2022)\n   - RETRO model and massive retrieval\n\n## Marcus's Recommendations\n\n### For Getting Started:\n1. Start with a managed vector DB (Pinecone, Weaviate Cloud)\n2. Use OpenAI embeddings initially\n3. Focus on chunking strategy before optimizing retrieval\n4. Build evaluation early\n\n### Common Mistakes:\n1. Over-engineering the embedding model\n2. Ignoring metadata filtering\n3. Not testing with real user queries\n4. Forgetting about updates and deletes\n\n### When to Self-Host:\n- Data privacy requirements\n- High query volume (cost optimization)\n- Custom embedding models\n- Specific latency requirements\n\n## Our Take\n\nAfter the conversation with Marcus, we're even more convinced that:\n\n1. **Chunking is underrated** - Spend more time here than on embedding models\n2. **Hybrid search is essential** - Don't rely on semantic search alone\n3. **Evaluation is hard** - But necessary. Start simple and iterate\n4. **Managed services win early** - Self-host when you have specific constraints\n\n## Related Episodes\n\n- Episode 2: Understanding LLMs  - Foundation for RAG concepts\n- Episode 4: Agents vs Workflows  - When to add agentic behavior to RAG\n- Episode 5: Building MARIA  - How we implemented RAG in our agent"
}
